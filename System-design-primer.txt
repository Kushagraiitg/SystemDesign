System design
1. Scalability
	1. Clones: LB+CLuster
		- ensure deployment
		- state/session stored in external DB or external cache
	2. Database
		- SQL
			- Master-Slave replication
			- sharding, denormalization, SQL tuning
		- noSQL
			- joins inside app
	3. Cache
		- memcache/redis
		- cached query
	4. Asynchronism
		- anything time consuming should be done asynchronously
2. Performance vs Scalability
	A service is said to be scalable if when we increase the resources in a system, it results in increased performance in a manner proportional to resources added.
	For the systems we build we must carefully inspect along which axis we expect the system to grow, where redundancy is required, and how one should handle heterogeneity in this system, and make sure that architects are aware of which tools they can use for under which conditions, and what the common pitfalls are.
	Performance problems- System is slow for every request
	Scalability problem- System is slow when scale increases
3. Latency vs Throughput
	maximum throughput with acceptable latency
4. CAP theorem
	- consitency, availability and partition tolerance, only 2 of the 3 are possible in every case
	- Centralized Systems - CA
	- Distributed Systems - CP/AP
	- Consistency - Every read receives the most recent write or an error
	- Availability - Every request receives a response, without guarantee that it contains the most recent version of the information
	- Partition Tolerance - The system continues to operate despite arbitrary partitioning due to network failures
	- Availability Patterns
		- Fail-over
			Active Passive
				heartbeats from active and passive servers
				downtime decided by whether passive are hot or not need start up from cold standby
				master-slave failover
			Active Active
				both servers serving traffic
				master master failover
		- replication
			- Master slave
			- Tree replication
			- Master-Master
			- Buddy replication
		Availability (Total) = Availability (Foo) * Availability (Bar)
	- Consistency Patterns
		- Weak consistency
			VoIP, video chat, realtime multiplayer games
		- Eventual consistency
			DNS, email
		- Strong consistency
			file systems and RDBMS, transactions
5. Domain Name System
	System->ISP->RootDNS->gives IP to ISP->give IP to system-> calls
	A Domain Name System (DNS) translates a domain name such as www.example.com to an IP address.

	DNS is hierarchical, with a few authoritative servers at the top level. Your router or ISP provides information about which DNS server(s) to contact when doing a lookup. Lower level DNS servers cache mappings, which could become stale due to DNS propagation delays. DNS results can also be cached by your browser or OS for a certain period of time, determined by the time to live (TTL).

	NS record (name server) - Specifies the DNS servers for your domain/subdomain.
	MX record (mail exchange) - Specifies the mail servers for accepting messages.
	A record (address) - Points a name to an IP address.
	CNAME (canonical) - Points a name to another name or CNAME (example.com to www.example.com) or to an A record.
	Services such as CloudFlare and Route 53 provide managed DNS services. Some DNS services can route traffic through various methods:
		1. Round robin
		2. Weighted Round robin
		3. least connections
		4. Weighted least connection
		5. latency based routing
		6. geolocation based routing
	Disadvantages:
		1. extra latency
		2. heavy management
		3. DDoS attacks
6. Content Delivery Network
	A content delivery network (CDN) is a globally distributed network of proxy servers, serving content from locations closer to the user. Generally, static files such as HTML/CSS/JS, photos, and videos are served from CDN, although some CDNs such as Amazon's CloudFront support dynamic content. The site's DNS resolution will tell clients which server to contact.
	Push CDNs-less updated content
	Pull CDNs- heavier traffic well supported
	Advantage
		Increases speed of response
		decreases load on main server
		increases uptime for main server
		increases security for communication
	Disadvantage(s): CDN
		CDN costs could be significant depending on traffic, although this should be weighed with additional costs you would incur not using a CDN.
		Content might be stale if it is updated before the TTL expires it.
		CDNs require changing URLs for static content to point to the CDN.
7. Load Balancers
		Load balancers distribute incoming client requests to computing resources such as application servers and databases. In each case, the load balancer returns the response from the computing resource to the appropriate client. 
		Load balancers are effective at:
			Preventing requests from going to unhealthy servers
			Preventing overloading resources
			Helping to eliminate a single point of failure
			Load balancers can be implemented with hardware (expensive) or with software such as HAProxy.
		Additional benefits include:
			SSL termination - Decrypt incoming requests and encrypt server responses so backend servers do not have to perform these potentially expensive operations
			Removes the need to install X.509 certificates on each server
			Session persistence - Issue cookies and route a specific client's requests to same instance if the web apps do not keep track of sessions
		To protect against failures, it's common to set up multiple load balancers, either in active-passive or active-active mode.
		Load balancers can route traffic based on various metrics, including:
			Random
			Least loaded
			Session/cookies
			Round robin or weighted round robin
			Layer 4: Layer 4 load balancers look at info at the transport layer to decide how to distribute requests. Generally, this involves the source, destination IP addresses, and ports in the header, but not the contents of the packet. Layer 4 load balancers forward network packets to and from the upstream server, performing Network Address Translation (NAT).
			Layer 7: Layer 7 load balancers look at the application layer to decide how to distribute requests. This can involve contents of the header, message, and cookies. Layer 7 load balancers 				terminate network traffic, reads the message, makes a load-balancing decision, then opens a connection to the selected server. For example, a layer 7 load balancer can direct video traffic to servers that host videos while directing more sensitive user billing traffic to security-hardened servers.
				At the cost of flexibility, layer 4 load balancing requires less time and computing resources than Layer 7, although the performance impact can be minimal on modern commodity 				hardware.
		Supports horizontal scaling
		Disadvantages:
			new POF
			complexity
			single LB=SPOF		
		
8. Reverse Proxy
	A reverse proxy is a server that:
		Receives client requests
		Forwards them to one or more backend servers
		Gets the response
		Sends the response back to the client
		To the client, it appears as one single server.
	Benefits:
		increased security
		can scale servers and cfg change
		SSL termination: decrypt input and encrypt output, servers dont need to install X.509 certs
		compression
		caching
		serves static content
	LB vs Reverse Proxy
		LB when there are multiple server
		Layer & reverse proxy and LB supported by NGINX and HAProxy
	Disadvantaes
		complexity, time increases
		SPOF
9. Application Layer
	Web layer vs platform/Application layer
		Microservices:  microservice architecture is an architectural pattern that organizes an application into a collection of loosely coupled, fine-grained services that communicate through lightweight protocols. This pattern is characterized by the ability to develop and deploy services independently, improving modularity, scalability, and adaptability. closely associated with principles such as domain-driven design, decentralization of data and governance, and the flexibility to use different technologies for individual services to best meet their requirements.
		Service Discovery: Systems such as Consul, Etcd, and Zookeeper can help services find each other by keeping track of registered names, addresses, and ports.
	
10 Database
	RDBMS
		collection of data items organized in tables
		ACID
			Atomicity
			Consistency
			Isolation
			Durability
		scaling a RDBMS
			master-slave
			master-master
			federation
			sharding
			denormalization
			SQL tuning
			
	NOSQL
		key-value store
		document store
		wide column store
		graph db
		BASE-Basically available Soft state eventual consistency
	
	Reasons for SQL:

	Structured data
	Strict schema
	Relational data
	Need for complex joins
	Transactions
	Clear patterns for scaling
	More established: developers, community, code, tools, etc
	Lookups by index are very fast
	Reasons for NoSQL:

	Semi-structured data
	Dynamic or flexible schema
	Non-relational data
	No need for complex joins
	Store many TB (or PB) of data
	Very data intensive workload
	Very high throughput for IOPS
	
	1. Redis
		Redis (Remote Dictionary Server) is an open-source (BSD licensed), in-memory database, often used as a cache, message broker, or streaming engine. It has rich support for data structures, including basic data structures like String, List, Set, Hash, SortedSet, and probabilistic data structures like Bloom Filter, and HyperLogLog. 

		Redis Architecture Overview
			Data Structures

			Redis stores all key-value pairs in an in-memory hash table, where each entry points to the actual key and value.
			It supports rich value data types such as:

			Strings

			Lists

			Sets

			Sorted Sets

			Hashes

			Bitmaps / HyperLogLogs / Streams (extended types)

			These structures allow Redis to serve diverse use cases efficiently.

			Core Operations

			Redis offers fast, atomic operations tailored to each data type. Basic CRUD-style operations include:

			GET ‚Äì Read the value of a key

			SET/PUT ‚Äì Create or update a key-value pair

			DEL ‚Äì Delete a key

			Data-structure-specific operations (e.g., list push/pop, set membership, hash field updates) are a major reason for Redis‚Äôs high performance and flexibility.

			Persistence

			Redis keeps data in memory but offers two persistence mechanisms:

			RDB (Redis Database Snapshot): Periodic snapshots of the dataset

			AOF (Append Only File): Logs every write operation for more durable persistence

			Both can be combined for faster recovery and stronger durability.

			High Availability ‚Äì Leader‚ÄìFollower

			Redis supports high availability through replication:

			A leader node handles writes.

			Follower nodes asynchronously replicate data and serve read requests.

			If the leader fails, tools like Redis Sentinel or Redis Cluster can promote a follower to leader, ensuring minimal downtime.
			
		Memcache
			Memcached ‚Äì Architecture Summary (Important Points)
				1. High-Level Architecture

				Distributed, In-Memory Key‚ÄìValue Store

				Data is stored purely in RAM for ultra-fast retrieval.

				Designed to reduce database load and improve application performance.

				Client-side Sharding

				Memcached servers don‚Äôt communicate with each other.

				The client library decides which server stores a key (usually via hashing).

				2. Core Components
				A. Client

				Performs hashing to map keys ‚Üí specific Memcached node.

				Handles retries, failover logic.

				Popular hashing methods:

				Modulo hashing (simple but bad for cluster changes)

				Consistent hashing (preferred; minimal key remapping)

				B. Memcached Server

				Internal server architecture includes:

				Threaded architecture

				One listener thread to accept connections.

				Multiple worker threads to handle requests.

				Slab allocator

				Memory divided into ‚Äúslabs‚Äù and ‚Äúchunks‚Äù to avoid fragmentation.

				Hash table

				Stores key‚Äìvalue entries.

				LRU eviction

				Evicts least-recently-used items when slab memory is full.

				3. Data Handling
				Data Storage

				Key ‚Üí Up to 250 bytes.

				Value ‚Üí Arbitrary bytes (strings, JSON, serialized objects).

				Operations

				get, set, add, replace, delete

				Atomic ops: incr, decr

				Expiration

				TTL eviction supported.

				No persistence

				Purely in-memory.

				All data lost on:

				Crash

				Restart

				4. Scaling Architecture
				Horizontal Scaling

				Add more servers to the cluster.

				Clients automatically distribute keys across nodes.

				Cache Partitioning

				No replication.

				Each key lives on exactly one node.

				Failure Handling

				If a node fails, all keys on that node are lost.

				Clients must handle:

				Timeout

				Retry to next server

				Rebuilding cache on demand (‚Äúcache miss storm‚Äù)

				5. Performance Characteristics

				Very low latency (sub-millisecond).

				High throughput (millions of ops/sec with enough nodes).

				Lightweight protocol (text or binary).

				6. Typical Use Cases

				Database query caching (SQL results)

				API response caching

				Session caching

				Computation caching

				Rate limiting metadata (lightweight, ephemeral)

				7. When Not to Use Memcached

				Need for persistence ‚Üí use Redis

				Complex data structures ‚Üí Redis

				High availability / replication ‚Üí Redis

				Large values or large memory capacity

				Frequent memory fragmentation concerns

				8. Memcached vs Redis (Quick Compare)
				Feature	Memcached	Redis
				Persistence	‚ùå No	‚úî Optional
				Data types	Simple key-value	Rich structures
				Memory	Slab allocator	Pointer-based
				Replication	‚ùå	‚úî
				Use case	Raw speed for simple caching	More features, durability
		
		MongoDB
			MongoDB ‚Äì Architecture Summary (Important Points)
			1. High-Level Architecture

			Document-oriented NoSQL database

			Stores data as BSON documents (binary JSON).

			Flexible schema

			Collections without enforced schema ‚Üí easy iteration.

			Distributed by design

			Built-in scaling, replication, sharding, and failover.

			2. Core Components
			A. MongoDB Server (mongod)

			Handles:

			Query execution

			Storage engine

			Replication

			Sharding

			WiredTiger cache management

			B. Storage Engine (WiredTiger ‚Äì default)

			Document-level concurrency control.

			Uses B-Tree for indexes.

			Supports compression (snappy/zstd/lz4).

			Has its own cache (50% of RAM default).

			C. MongoS Router (Sharded Clusters)

			Stateless routing component.

			Determines the correct shard for each request.

			Connects clients to distributed data.

			D. Config Servers (Sharded Clusters)

			Store cluster metadata:

			Shard list

			Chunk distribution

			Routing tables

			Always deployed as a Config Server Replica Set (CSRS).

			3. Replication Architecture

			MongoDB uses Replica Sets for HA.

			Replica Set Components

			Primary

			Accepts writes.

			Replicates oplog entries to secondaries.

			Secondaries

			Replicate from primary.

			Can serve reads (if enabled).

			Arbiter (optional)

			Participates in elections, stores no data.

			Key Mechanisms

			Oplog-based replication

			Operations recorded in capped ‚Äúoplog‚Äù collection.

			Automatic failover

			When primary fails, an eligible secondary gets elected.

			Write Concerns

			Control acknowledgment level (e.g., w:1, w:majority).

			4. Sharding Architecture

			Used for horizontal scaling.

			How Sharding Works

			Collection is partitioned into chunks.

			Chunks distributed across shards.

			Clients ‚Üí MongoS ‚Üí appropriate shard.

			Shard Keys

			Critical for performance:

			Range-based sharding (good for sequential workloads, risk of hotspots)

			Hashed sharding (prevents hotspots; uniform distribution)

			Zonal sharding (location-based)

			Shard Components

			Each shard itself is typically a replica set.

			5. Query Execution

			MongoDB query engine uses:

			Index selection (B-tree indexes)

			Aggregation pipeline (stages like $match, $group, $sort)

			Query planner that evaluates multiple plans ‚Üí picks optimal

			Memory limits for in-memory sorts/aggregations

			6. Storage, Caching & Write Path
			Write Path

			Client sends write

			Primary validates & applies

			Record added to oplog

			Acknowledgment based on write concern

			Secondaries pull oplog and replicate

			WiredTiger Cache

			Used for hot data pages.

			Not the same as Linux OS page cache (but uses both).

			Journal & Durability

			Journaling on by default for crash recovery.

			Write-ahead logging model.

			7. Performance Characteristics

			Great for: JSON-like workloads, high write throughput, flexible schema.

			Indexes improve read performance, but too many slow writes.

			Horizontal scale-out with sharding.

			8. When NOT to Use MongoDB

			Avoid when:

			Strong ACID transactions across many documents required.

			Heavy relational joins needed.

			Predictable schema and complex relational constraints.

			Very high multi-document transactional integrity.

			9. MongoDB vs Relational DB (Quick Compare)
			Feature	MongoDB	Relational DB
			Schema	Flexible	Strict
			Joins	Limited ($lookup)	Strong
			Scaling	Horizontal built-in	Mostly vertical
			Transactions	Supported but costlier	Native, strong
			Data Model	Document (JSON)	Tables & rows
		
		Wide-Column Databases ‚Äì Brief Explanation

			A wide-column store is a NoSQL database that stores data in tables, rows, and dynamic columns, but with flexible schema and high scalability.

			Data is grouped into column families.

			Good for large, sparse datasets and horizontal scaling.

			Inspired by Google Bigtable.

			üìå Benefits of Wide-Column Databases

			‚úî Highly scalable (horizontal scale-out)

			‚úî Flexible schema (columns can vary per row)

			‚úî Efficient for sparse or large datasets

			‚úî High write throughput

			‚úî Distributed architecture ‚Üí fault-tolerant

			‚úî Good for time-series, IoT, logs, big data

			‚ö†Ô∏è Cons of Wide-Column Databases

			‚ùå More complex data modeling

			‚ùå Not ideal for ad-hoc queries

			‚ùå No joins / limited secondary indexing

			‚ùå Requires understanding of partition keys and column families

			‚ùå Consistency can be eventual (depending on implementation)

			üü¶ HBase ‚Äì Summary
			Brief Explanation

			Open-source implementation of Google Bigtable.

			Runs on top of HDFS (Hadoop).

			Strongly consistent.

			Designed for big data, massive tables, and high write throughput.

			Benefits

			‚úî Strong consistency

			‚úî Handles billions of rows efficiently

			‚úî Great for batch + random read/write

			‚úî Integrates seamlessly with Hadoop ecosystem

			‚úî Efficient for sparse datasets (column family storage)

			Cons

			‚ùå Requires Hadoop/HDFS ‚Üí heavier operational overhead

			‚ùå Not suitable for low-latency queries

			‚ùå Complex to manage (region servers, compactions)

			‚ùå No built-in SQL layer without tools

			Typical Usage

			Time-series databases

			IoT data ingestion

			Massive log storage

			Large analytical systems within Hadoop

			Use cases needing strong consistency + huge scale

			üüß Cassandra ‚Äì Summary
			Brief Explanation

			Wide-column NoSQL database inspired by Dynamo + Bigtable.

			Masterless architecture (peer-to-peer).

			Tunable consistency.

			Benefits

			‚úî Very high write throughput

			‚úî Extremely high availability (no single primary)

			‚úî Multi-region replication built-in

			‚úî Tunable consistency (choose strong/eventual per query)

			‚úî Easy to scale linearly (add nodes ‚Üí capacity grows)

			Cons

			‚ùå Complex modeling (data model tied to query patterns)

			‚ùå Eventual consistency by default

			‚ùå No ad-hoc querying (must design tables per query)

			‚ùå Hard deletes due to tombstones

			‚ùå Writes can pile up if compaction isn't tuned

			Typical Usage

			Real-time applications needing uptime

			Messaging systems

			Time-series and metrics storage

			E-commerce carts

			IoT & sensor data

			Multi-datacenter deployments requiring HA + low latency

			üîé Quick Comparison (HBase vs Cassandra)
			Feature	HBase	Cassandra
			Architecture	Master-based (HMaster)	Masterless (P2P)
			Consistency	Strong	Tunable (default eventual)
			Storage	HDFS-based	LSM-based
			Best For	Big data + Hadoop	Low-latency, multi-region apps
			Scalability	Very high	Extremely high
			Ops Complexity	High	Moderate
						
		Graph Databases ‚Äì Brief Explanation

			A graph database stores data as nodes, edges, and properties, optimized for representing and querying relationships.

			Nodes = entities (users, products)

			Edges = relationships (friends, purchased, follows)

			Properties = attributes on nodes/edges

			Queries use graph traversal instead of joins.

			Graph DBs are ideal when relationships are as important as the data itself.

			üìå Benefits of Graph Databases

			‚úî Excellent for relationship-heavy data

			‚úî Very fast traversal (no expensive joins)

			‚úî Flexible schema

			‚úî Natural modeling of real-world networks: social, fraud, identity graphs

			‚úî Supports deep queries like shortest paths, influence chains

			‚úî Often provide Cypher / Gremlin query languages

			‚ö†Ô∏è Cons of Graph Databases

			‚ùå Not ideal for bulk analytical workloads

			‚ùå Harder horizontal scaling (compared to NoSQL stores)

			‚ùå May require domain expertise to model graphs well

			‚ùå Some graph DBs struggle with distributed transactions

			‚ùå Writes can be slower when deeply connected structures update

			üéØ Typical Usage of Graph DBs

			Social networks

			Fraud detection

			Recommendation engines

			Identity/authorization graphs

			Knowledge graphs

			Network & IT asset modeling

			Supply chain graphs

			Dependency modeling (packages, microservices)

			üî• Very Popular Graph Databases
			ü•á 1. Neo4j

			Most widely used native graph database.

			Uses Cypher query language.

			Strong for complex relationships and deep traversal.

			ü•à 2. Amazon Neptune

			Managed graph DB in AWS.

			Supports both Gremlin and SPARQL.

			Good for enterprise-scale knowledge graphs.

			ü•â 3. JanusGraph

			Open-source, scalable distributed graph DB.

			Can run on Cassandra, DynamoDB, Scylla, or HBase.

			Supports Gremlin graph queries.
	
	CAP for DBs
		CP-MongoDB, HBase, Spanner
		AP-Cassandra, DDB
		CA-Rare, only when no partitioning
		
	Indexing
		Indexing ‚Äî SDI-Friendly Explanation

		Indexes are data structures that make reads faster by allowing the database or storage engine to avoid scanning all records. They work like the index of a book: instead of flipping through every page, you jump directly to where the data lives.

		In system design, indexing decisions directly affect latency, throughput, storage costs, and write performance.

		üîë Why Indexes Matter in System Design
		Indexes improve read performance

		Reduce lookup time from O(n) to O(log n) or even O(1) depending on index type.

		Critical for high-read systems (feeds, search, recommendation systems, user profile lookups).

		Indexes hurt write performance

		Every insert/update/delete must also update the index.

		More indexes ‚Üí slower writes.

		Important in high-write systems (logging, messaging, analytics ingestion).

		Indexes require more storage

		Often 10‚Äì30% additional storage.

		Must be considered when designing large-scale systems.

		üìö Types of Indexes (SDI Context)
		1. B-Tree Index (Most common)

		Default index in SQL databases.

		Balanced tree structure.

		Supports:

		Equality queries (WHERE id = 5)

		Range queries (BETWEEN, <, >, timestamps)

		Sorting

		Used in: MySQL, PostgreSQL, SQLite, many NoSQL engines (MongoDB's b-tree variant).

		When to use:

		User lookups

		Time-based queries

		‚ÄúGet recent posts‚Äù, ‚ÄúGet messages between t1 and t2‚Äù

		2. Hash Index

		Uses a hash table.

		O(1) lookup for equality.

		But does NOT support range queries because hashing destroys ordering.

		When to use:

		Caches (Redis)

		Key-value stores

		Equality-only lookups:

		SELECT * FROM users WHERE email = 'x'

		3. Bitmap Index

		Each distinct value gets a bitmap.

		Great for low-cardinality columns (few unique values).

		Used in analytics systems (Druid, ClickHouse, Redshift).

		When to use:

		Gender, status flags, boolean fields

		Large analytical scans with filtering

		4. Full-Text Index

		Supports word and phrase search.

		Tokenization + inverted index.

		When to use:

		Search boxes

		Blogs, ecommerce search

		Anything requiring relevance ranking

		5. Secondary Index

		Any index that is not the primary key index.

		Common in NoSQL where primary key is often the only default index.

		When to use:

		You need to query by a field that is not the main key

		E.g., MongoDB: indexing email in addition to _id

		6. Composite Index

		Index on multiple columns.

		Example: (user_id, created_at)

		Notes:

		Order matters: prefix rule
		(a, b) can index queries on a or (a,b) but NOT on b alone.

		When to use:

		Fetch latest posts for a user

		Query using multiple filtering conditions

		‚öñÔ∏è Tradeoffs (Important for SDI!)
		Pros

		‚úî Huge improvement in read latency
		‚úî Reduced load on DB
		‚úî Essential for large-scale systems

		Cons

		‚úó Slows down writes (extra work per insert/update/delete)
		‚úó Consumes more storage
		‚úó Must be carefully chosen‚Äîevery unnecessary index costs performance

		üß† What to Say in a System Design Interview

		Here‚Äôs a clean, interview-ready statement:

		‚ÄúWe should add a B-tree index on the timestamp and user_id to support range queries. However, indexes slow down writes, so we need to be selective. Since this service is read-heavy, the tradeoff is acceptable. For text search, we‚Äôd rely on a full-text inverted index, likely via Elasticsearch.‚Äù


11. Cache
	- helps absorb uneven loads and spikes
	- client caching
		client
		browser
		distinct cache layer
	- CDN caching
	- Web Server caching
	- DB caching
	- Application caching
		- memcache
		- redis
		- cache invalidation-LRU
		- caching at DB query
		- caching at object level
			user session
			fully rendered webpage
			activity streams
			user graph data
	- When to update cache
		- cache aside
		- write through cache
		- write back
		- refresh ahead
		



	

	
